

# Poll Automation App

Poll Automation App is a standalone, open-source web application designed to intelligently generate and manage live polls in real-time during lectures, webinars, or meetings‚Äîwithout being tied to any specific video conferencing platform.

## ‚öôÔ∏è Project Pipeline

[![](https://mermaid.ink/img/pako:eNqVlVtu2zgUhrdCsCjQYqRAki3L1gAFrNtMB3HrRgEC1O4DIzERJzIpkFQTT5otdAt96QK7hJKipMTTFoX9YOicQ37nwh_kPSxYiWEIr2p2W1SIS3B6tqVA_Z4_B8u2JAzkrOUFNs4VKTbfvnz-Cv5mQvbx17Rp5YcwDHekALb96tMWnuGC8ZLQa_CRILDCJUHGhfkWfgLLTcYZlZiWwNZIzpqKUZxLjtEOc8266hds6VjNukICAzcE-fk5eJE3GBeVLZl9ju_kS7Nq2efPpe7kDxARivje1KkTR5sIFTcm7xvV-Mm_AlzkIMf8o0l7acKGFvW0jPFbxEuwjlcgrlp6IzQr3lxURDSYd9tJgRUzQ0Iu16-7BtQnaoghxT3pnCMqCk4aSRgF_-Rv33RVHaZLd0SCMyzaWnbju8CXOVNlyW50PwzEC8Hp6Qq8a7HoqH9hijnSn4fYXLf9WMCYPdmsWV2rXR3G_gHEusHU9c7gkh7XR3E5bhA_6SWv2O3hgnTTSSdBorpkeqq26hUVnYAqFTH707HoGhdPk_wkx7oVFZAM6DZ0ONvksi0x_UUSYYKGkY2CMTvU2BtVKB56GWedy32t9GzsokZCJPgKaMVfkboOn2VZGqWpJSRnNzh8FgVu7MZWwWrGR8sE7VtSyir0mjuL34WuY_G9-v_zf-RB_z0-dbIgW454x5k5s-mA761j8L3Ox-KzSeqM9DSbxY4z0HvrqOKN9ofa55mfLka6lwbJxBvovXUMXUlxqDtOp2k8kmPPnfvRQO6tY8haf0PRbuZnj-fpeEEQJePAjXUMulfd48CTNBjp2WI59_yB3lu_oT_h6ytUS_FpTnUVDhI6cEfD0R944-HIDryJHvWBJ-1GdODKhtaUF1pQXd87REr1otzrVVsoK7zDWxiqzxLxmy3c0ge1DrWS5XtawFDyFluQs_a6gurWrIWy2qZUV0tC0DVHu9HbIPqesd2wRZkwvId3MLTduXsyCRx_Og0Wk4XvTAML7mGoFHASTJzZzPecmefNfP_Bgv91COdk4c_n3mLhOGq96_sTC6pnSt12K_Mgdu-iBa-5bqavUY0N85i1VCq2Fzx8B4HXS30?type=png)](https://mermaid.live/edit#pako:eNqVlVtu2zgUhrdCsCjQYqRAki3L1gAFrNtMB3HrRgEC1O4DIzERJzIpkFQTT5otdAt96QK7hJKipMTTFoX9YOicQ37nwh_kPSxYiWEIr2p2W1SIS3B6tqVA_Z4_B8u2JAzkrOUFNs4VKTbfvnz-Cv5mQvbx17Rp5YcwDHekALb96tMWnuGC8ZLQa_CRILDCJUHGhfkWfgLLTcYZlZiWwNZIzpqKUZxLjtEOc8266hds6VjNukICAzcE-fk5eJE3GBeVLZl9ju_kS7Nq2efPpe7kDxARivje1KkTR5sIFTcm7xvV-Mm_AlzkIMf8o0l7acKGFvW0jPFbxEuwjlcgrlp6IzQr3lxURDSYd9tJgRUzQ0Iu16-7BtQnaoghxT3pnCMqCk4aSRgF_-Rv33RVHaZLd0SCMyzaWnbju8CXOVNlyW50PwzEC8Hp6Qq8a7HoqH9hijnSn4fYXLf9WMCYPdmsWV2rXR3G_gHEusHU9c7gkh7XR3E5bhA_6SWv2O3hgnTTSSdBorpkeqq26hUVnYAqFTH707HoGhdPk_wkx7oVFZAM6DZ0ONvksi0x_UUSYYKGkY2CMTvU2BtVKB56GWedy32t9GzsokZCJPgKaMVfkboOn2VZGqWpJSRnNzh8FgVu7MZWwWrGR8sE7VtSyir0mjuL34WuY_G9-v_zf-RB_z0-dbIgW454x5k5s-mA761j8L3Ox-KzSeqM9DSbxY4z0HvrqOKN9ofa55mfLka6lwbJxBvovXUMXUlxqDtOp2k8kmPPnfvRQO6tY8haf0PRbuZnj-fpeEEQJePAjXUMulfd48CTNBjp2WI59_yB3lu_oT_h6ytUS_FpTnUVDhI6cEfD0R944-HIDryJHvWBJ-1GdODKhtaUF1pQXd87REr1otzrVVsoK7zDWxiqzxLxmy3c0ge1DrWS5XtawFDyFluQs_a6gurWrIWy2qZUV0tC0DVHu9HbIPqesd2wRZkwvId3MLTduXsyCRx_Og0Wk4XvTAML7mGoFHASTJzZzPecmefNfP_Bgv91COdk4c_n3mLhOGq96_sTC6pnSt12K_Mgdu-iBa-5bqavUY0N85i1VCq2Fzx8B4HXS30)

## üìÅ Monorepo Project Structure (Turborepo)

```
poll-automation/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ backend/                    # Node.js + Express backend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/           # LLM forwarding, WebSocket handling
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web/                # REST API routes, controllers, models
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ws/                 # WebSocket server for audio streaming
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .env                    # Backend environment variables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ frontend/                   # React + TypeScript + Vite frontend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/         # Reusable UI components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/              # Page components (e.g., AudioCapture, GuestPage)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription/      # Audio recording and transcription utils
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ contexts/           # React context for auth, theme, loading
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .env                    # Frontend environment variables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ whisper/                    # Python FastAPI Whisper transcription service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/              # Whisper model loader
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket/          # WebSocket handler for transcription
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .env                    # Whisper service environment variables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ pollgen-llm/                # Python FastAPI LLM service for poll generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_transcripts/     # Sample transcript data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .env                    # LLM service environment variables
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îî‚îÄ‚îÄ types/                      # Shared TypeScript types
‚îú‚îÄ‚îÄ .gitignore                      # Git ignore rules
‚îú‚îÄ‚îÄ package.json                    # Monorepo package configuration
‚îú‚îÄ‚îÄ pnpm-workspace.yaml             # pnpm workspace configuration
‚îú‚îÄ‚îÄ turbo.json                      # Turborepo configuration
‚îî‚îÄ‚îÄ README.md                       # This file
```

## üöÄ Getting Started

### üîß Prerequisites

- **Node.js**: v18 or higher
- **pnpm**: v8 or higher (`npm install -g pnpm`)
- **Turborepo**: Install globally (`pnpm add -g turbo`)
- **Python**: 3.9 or higher
- **MongoDB**: Running locally on `mongodb://localhost:27017`
- **Ollama**: For local LLM support (optional)

### üîß Python Environment Setup

#### Whisper Service

1. **Navigate to the Whisper service folder:**

```bash
cd services/whisper
```

2. **Create and activate a Python virtual environment:**

```bash
# Windows
python -m venv whisper-env
whisper-env\Scripts\activate

# macOS/Linux
python3 -m venv whisper-env
source whisper-env/bin/activate
```

3. **Install dependencies:**

   - **For CPU-only:**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

   - **For GPU support (CUDA 12.1):**

```bash
pip install -r requirements.gpu.txt --extra-index-url https://download.pytorch.org/whl/cu121
```

#### Pollgen-LLM Service

1. **Navigate to the Pollgen-LLM service folder:**

```bash
cd services/pollgen-llm
```

2. **Create and activate a Python virtual environment:**

```bash
# Windows
python -m venv pollgenenv
pollgenenv\Scripts\activate

# macOS/Linux
python3 -m venv pollgenenv
source pollgenenv/bin/activate
```

3. **Install dependencies:**

```bash
pip install -r requirements.txt
```

### üîë Setting up Gemini API Key

1. Visit [https://ai.google.dev/](https://ai.google.dev/) and sign in with your Google account.
2. Click **‚ÄúGet API key‚Äù** and copy the key.
3. Add it to `services/pollgen-llm/.env`:

```env
GEMINI_API_KEY=<your key>
```

### üß† Setting up Local LLM (Ollama)

1. **Download and Install Ollama:**

   - Visit [https://ollama.com](https://ollama.com/) and download the installer.
   - Follow the setup wizard to complete installation.

2. **Verify Ollama Installation:**

```bash
ollama --version
```

3. **Pull Required Models:**

```bash
ollama pull llama3.2
ollama pull mxbai-embed-large
```

4. **Confirm Model Names:**

```bash
ollama list
```

### üîß .env Configuration

#### `apps/backend/.env`

```env
PORT=3000
WHISPER_WS_URL=ws://127.0.0.1:8000
LLM_FORWARD_URL=ws://127.0.0.1:5001/ws/llm
MONGO_URI=mongodb://localhost:27017/pollgen
JWT_SECRET=your_jwt_secret_here

# Email Configuration (for development - uses Gmail SMTP)
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_USER=your_email@gmail.com
EMAIL_PASS=your_app_password_here
SENDER_EMAIL=noreply@your-app.com

# Frontend URL for password reset links
FRONTEND_URL=http://localhost:5173
```

#### `apps/frontend/.env`

```env
VITE_BACKEND_WS_URL=ws://localhost:3001/transcription
VITE_PORT=5173
VITE_BACKEND_API_URL=http://localhost:3000
VITE_SOCKETIO_URL=http://localhost:3000
VITE_CHUNK_INTERVAL=30000
VITE_BACKEND_WS_URL_GUEST=ws://localhost:3001/transcription
```

#### `services/whisper/.env`

```env
WHISPER_MODEL_SIZE=small
BUFFER_DURATION_SECONDS=60
WHISPER_SERVICE_PORT=8000
```

Available Whisper model sizes: `tiny`, `base`, `small`, `medium`, `large-v1`, `large-v2`, `large-v3`.

#### `services/pollgen-llm/.env`

```env
GEMINI_API_KEY=<your Gemini API key>
MONGO_URI=mongodb://localhost:27017
HOME=<your home directory, e.g., "C:\Users\YourUsername">
```

### üõ†Ô∏è Monorepo Setup

1. **Install global dependencies:**

```bash
npm install -g pnpm
pnpm add -g turbo
```

2. **Install project dependencies:**

```bash
pnpm install
```

3. **Start all development servers:**

```bash
pnpm dev
```

This starts:
- ‚úÖ *Frontend*: [http://localhost:5173](http://localhost:5173)
- ‚úÖ *Backend API*: http://localhost:3000
- ‚úÖ *Backend WebSocket*: ws://localhost:3001
- ‚úÖ *Whisper Transcription Service*: ws://localhost:8000
- ‚úÖ *Pollgen-LLM Service*: ws://localhost:5001/ws/llm

> Ensure Python environments for `whisper` and `pollgen-llm` are activated.

### üõÜ Using Turborepo

- `pnpm build`: Build all apps/services
- `pnpm lint`: Lint all projects
- `pnpm test`: Run tests
- `turbo run <task>`: Run any task across monorepo

## üó£Ô∏è Phase 1 ‚Äì Transcription Pipeline

The real-time transcription flow:
1. **Frontend** captures audio via `AudioCapture.tsx` or `GuestPage.tsx`, sending `.wav` chunks over WebSocket.
2. **Backend** WebSocket server (`ws-server.ts`) forwards audio to the Whisper service.
3. **Whisper Service** processes audio using Faster-Whisper, returning JSON transcriptions.
4. **Backend** forwards transcriptions to `pollgen-llm` for poll generation or back to the frontend for display.

> Transcriptions are displayed in real-time on `AudioCapture` and `GuestPage` via `LiveTranscriptFeed.tsx`.

## üß† Phase 2 ‚Äì LLM-based Poll Generation

The poll generation flow:
1. **Backend** buffers transcriptions (`llm-forwarder.ts`) and sends chunks to `pollgen-llm` via WebSocket.
2. **Pollgen-LLM** uses Gemini or Ollama to generate poll questions based on transcript text and settings (e.g., question type, frequency).
3. **Generated questions** are stored in MongoDB (`pollgen.pollquestions`) and can be retrieved via the backend API.
4. **Frontend** displays AI-generated questions in `AIQuestionFeed.tsx` or allows manual poll creation in `CreateManualPoll.tsx`.

## üìä Phase 3 ‚Äì Realtime Poll Launch and Analytics

- **Poll Launch**: Hosts can launch polls via `CreatePollPage.tsx` or view AI-generated polls in `AIQuestionFeed.tsx`.
- **Participant Tracking**: `Participants.tsx` tracks real-time poll participation.
- **Leaderboard**: `Leaderboard.tsx` and `StudentLeaderboard.tsx` display live rankings.
- **Analytics**: `Reports.tsx` provides detailed poll performance metrics.

## üì¶ Tech Stack

### Backend
- **Node.js + Express + TypeScript**: REST API and WebSocket server
- **MongoDB**: Stores poll configurations and questions
- **WebSocket**: Real-time audio and transcription streaming

### Frontend
- **React 19 + TypeScript + Vite**: Fast, modern frontend
- **TailwindCSS**: Styling
- **React Router**: Navigation
- **Recharts**: Data visualization
- **Framer Motion**: Animations
- **React Hook Form**: Form handling

### Services
- **Whisper Service**: Python FastAPI with Faster-Whisper for transcription
- **Pollgen-LLM**: Python FastAPI with Gemini or Ollama for poll generation

## üõ†Ô∏è Features

- **Real-time Transcription**: Live audio capture and transcription for hosts and guests
- **AI Poll Generation**: Automatic poll creation based on lecture content
- **Manual Poll Creation**: Custom poll creation via `CreateManualPoll.tsx`
- **Dashboards**: Host (`HostDashboard.tsx`) and student (`StudentDashboard.tsx`) interfaces
- **Participant Tracking**: Real-time monitoring in `Participants.tsx`
- **Leaderboard**: Live rankings in `Leaderboard.tsx`
- **Analytics**: Detailed reports in `Reports.tsx`
- **Guest Access**: Simplified audio input for guests via `GuestPage.tsx`
- **Customizable Settings**: Question frequency, type, and difficulty controls

## üõ†Ô∏è Development Workflow

- **Turborepo**: Use `--filter` to target specific apps (e.g., `pnpm --filter @poll-automation/backend run dev`).
- **pnpm**: Add dependencies with `pnpm add <package> --filter <workspace>`.
- **Git**:
  - Work in feature branches (e.g., `git checkout -b feature/audio-streaming`).
  - Submit PRs to the `development` branch.
  - Include both transcription and web app teams in PR reviews.

<!-- ## üß™ Testing

- **Unit Tests**: Located in `apps/backend/__tests__` and `apps/frontend/src/__tests__`.
- **Integration Tests**: Cover backend ‚Üî Whisper ‚Üî LLM flows.
- Run tests: `pnpm test` -->

## üõ†Ô∏è Troubleshooting

- **pnpm Errors**: Run `pnpm install` in the root to sync dependencies.
- **WebSocket Issues**: Verify `WHISPER_WS_URL` and `LLM_FORWARD_URL` in `.env` files.
- **MongoDB Errors**: Ensure MongoDB is running on `mongodb://localhost:27017`.
- **Whisper Service**: Confirm the correct model size in `services/whisper/.env`.
- **TypeScript Errors**: Check `tsconfig.json` paths for `@poll-automation/types`.

<!-- ## üìÑ License

Internal use only. Contact project maintainers for details. -->

